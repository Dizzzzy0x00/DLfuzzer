以前的模糊测试，输入会被随机地变异生成不同的测试用例，或者是以AFL等模糊测试工具为代表的基于覆盖率引导的变异。这种随机变异的方法在测试效率和测试覆盖率上存在一定的局限性。一般来说，程序中的bug是非常稀有且不规律的分布在程序代码之中。大部分的fuzzer目标就是提高输入的代码覆盖率，去增加找到安全漏洞的几率。大部分现代的fuzzer使用进化算法去解决一个基础优化问题——生成新的输入使得其代码覆盖率最大化。进化算法从一堆种子输入开始，随机突变这些种子来生成新的测试输入，用这些新的测试数据来输入到目标程序中，并且只留下那些能发现未覆盖代码的测试数据。但是，当输入的语料库变大的同时，进化的过程变慢（指的是覆盖到新的代码区域），对应的一种解决思路是符号执行这样子的平滑技术，但是由于路径爆炸，不完全的环境模拟，符号建模占用大量内存等问题，符号执行并不能扩展到大型程序。由此，NEUZZ引入神经网络来解决：
NEUZZ使用一个基于RNN（循环神经网络）的神经网络来对程序进行学习和平滑处理。通过将输入样本和对应的代码路径作为训练数据，NEUZZ学习到输入样本在不同代码路径上的执行特征，并生成平滑的输入样本，从而提高测试用例的质量和多样性
NEUZZ在生成的平滑输入样本的基础上，采用了一种基于贪心策略的搜索算法（即梯度引导优化）来引导模糊测试的生成过程。这种策略会根据神经网络生成的平滑输入样本的特征，优先选择那些能够导致不同代码路径执行的测试用例。这样可以有效地提高测试用例的覆盖率和测试效率
在NN的在线微调环节中，NEUZZ根据神经网络输出的梯度信息，平滑处理当前的种子输入以生成新的输入样本。这一梯度信息能明确指出哪些部分在当前输入样本中对提高覆盖率具有更大的影响力，因而优选出梯度较大的部分进行平滑操作。这个流程确保了新生成的输入样本更可能引领模糊测试走向尚待探索的、更高覆盖率的路径。
NEUZZ基于神经网络的模糊测试方法的步骤：
初始种子生成：从程序的输入空间中随机生成一组初始种子输入作为模糊测试的起点。
程序执行与覆盖率收集：使用初始种子输入运行目标程序，并通过动态分析收集执行路径和代码覆盖率信息。
样本生成与筛选：根据收集到的执行路径和覆盖率信息，采用贪心搜索策略生成新的模糊测试样本。贪心搜索策略根据当前种子输入的覆盖率信息，对输入进行变异、交叉、替换等操作，生成新的输入样本。然后通过目标程序的执行，计算每个新生成样本的覆盖率，并将高覆盖率的样本筛选出来，作为下一轮迭代的种子输入。
神经网络训练：将筛选出的高覆盖率样本输入到神经网络中进行训练。神经网络通过学习输入样本和对应的覆盖率之间的关系，从而学习到输入样本的表示。
输入样本平滑：利用训练好的神经网络对新的输入样本进行平滑操作，即对输入样本进行一系列微小的变化，以生成平滑的输入样本。
生成新的种子输入：将平滑后的输入样本作为新的种子输入，重复步骤2到步骤5的过程，形成循环迭代的过程。 
NEUZZ核心思路

NEUZZ巧妙地将模糊测试中的路径探索任务变为一项优化问题。它利用神经网络模式来揭示输入样本与覆盖率的内在联系，并通过对输入样本的平滑操作来产生新的种子输入。这种平滑操作可以视作在输入空间中进行搜索，旨在找出导致目标程序中出现更高覆盖率的输入变化。因此，NEUZZ实际上是将路径探索任务转变为了在输入空间寻找高覆盖率输入的优化问题。
训练NN
NEUZZ采用两阶段的神经网络训练方法——离线预训练 & 在线微调
离线预训练：利用生成的初始种子输入和对应的覆盖率信息进行离线预训练。 将输入样本和对应的覆盖率信息作为训练数据，输入到神经网络中进行训练，使得神经网络能够初步学习到输入样本的特征和模式。 
在线微调：由于训练NN model的初始数据可能只覆盖到程序空间的一小部分，所以需要进一步通过增量训练来训练模型，NEUZZ使用进化式fuzzer生成的语料库来训练神经网络（原文：“Incremental learning”——增量训练），在fuzzing的过程中，新的程序行为可以被观察到。在增量训练中，主要面对的难题是，在训练新的数据的过程中，模型有可能完全忘记从旧数据中学习的规则。为了避免这个问题，NEUZZ设计了一种新的基于覆盖的过滤方案，这种方案会生成旧数据和新数据的简练的总结，使得NN model能高效地在其上面训练。
